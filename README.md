1. Подготовка и исследование данных
На стадии предобработки были очищены данные от пропущенных значений и повторяющихся записей, проведена кодировка категориальных признаков с использованием факторизации и one-hot-encoding.
2. Графичекий анализ, включающий построение гистограмм распределения, диаграмм размаха (boxplot), матриц корреляции и графиков частот встречаемости значений, позволил предварительно оценить
влияние признаков и зависимости.
3. обучено четыре модели: TabNet, XGBoost, LightGBM и CatBoost.
Для каждой из них подобраны оптимальные параметры, учитывая объём выборки и наличие дисбаланса классов, что позволило добиться устойчивой сходимости и высокой скорости обучения.
4.Для всех обученных моделей рассчитаны метрики качества: Accuracy, Precision, Recall, F1 Score, ROC AUC и Average Precision.
Анализ показал:
•	TabNet достиг максимального значения точности (Accuracy), однако его способность к выявлению положительных примеров (Recall) и качество прогноза (Precision) оказались ниже, что негативно сказалось на F1 Score.
•	Модель XGBoost показала наиболее сбалансированную производительность, обеспечив самый высокий F1 Score за счёт удачного сочетания Precision и Recall.
•	LightGBM и CatBoost продемонстрировали хорошие результаты по полноте (Recall), но уступили по точности, что также повлияло на финальный F1 Score.
5.Для всех моделей проведен анализ важности признаков с использованием встроенных инструментов интерпретации. Результаты представлены в виде графических визуализаций.
Особое внимание уделено модели TabNet, где был применён метод explain, позволяющий определить ключевые переменные, оказывающие влияние на прогноз модели.
